{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deteksi Objek\r\n",
        "\r\n",
        "*Deteksi objek* adalah bentuk Visi Komputer tempat model pembelajaran mesin dilatih untuk mengklasifikasikan setiap instans dari objek pada gambar, dan menunjukkan *kotak pembatas* yang menandai lokasinya. Anda dapat menganggap ini sebagai perkembangan dari *klasifikasi gambar* (di mana model menjawab pertanyaan \"gambar apakah ini?\") untuk membuat solusi agar kita dapat menanyakan pada model \"objek apa yang ada pada gambar ini, dan di mana mereka?\".\r\n",
        "\r\n",
        "![Robot mengidentifikasi buah](./images/object-detection.jpg)\r\n",
        "\r\n",
        "Misalnya, toko kelontong dapat menggunakan model deteksi objek untuk menerapkan sistem checkout otomatis yang memindai ban berjalan menggunakan kamera, dan dapat mengidentifikasi item tertentu tanpa perlu menempatkan masing-masing item pada ban dan memindainya satu per satu.\r\n",
        "\r\n",
        "Layanan kognitif **Custom Vision** di Microsoft Azure memberikan solusi berbasis awan untuk membuat dan memublikasikan model deteksi objek kustom.\r\n",
        "\r\n",
        "## Membuat sumber daya Custom Vision\r\n",
        "\r\n",
        "Untuk menggunakan layanan Custom Vision, Anda memerlukan sumber daya Azure yang dapat Anda gunakan untuk melatih model, dan sumber daya yang dapat dipublikasikan agar dapat digunakan aplikasi. Anda dapat menggunakan sumber daya yang sama untuk masing-masing tugas ini, atau menggunakan sumber daya berbeda untuk masing-masing guna mengalokasikan biaya secara terpisah yang diberikan kedua sumber daya yang dibuat di wilayah yang sama. Sumber daya untuk salah satu (atau keduanya) tugas dapat berupa sumber daya **Cognitive Services** umum, atau sumber daya **Custom Vision** khusus. Gunakan petunjuk berikut untuk membuat sumber daya **Custom Vision** yang baru. (Atau Anda dapat menggunakan sumber daya yang ada jika memiliki satu).\r\n",
        "\r\n",
        "1. Di tab browser baru, buka portal Azure di [https://portal.azure.com](https://portal.azure.com), dan masuk menggunakan akun Microsoft yang terkait dengan langganan Azure Anda.\r\n",
        "2. Pilih tombol **&#65291;Buat sumber daya**, cari *custom vision*, dan buat sumber daya **Custom Vision** dengan pengaturan berikut:\r\n",
        "    - **Buat opsi**: Keduanya\r\n",
        "    - **Langganan**: *Langganan Azure Anda*\r\n",
        "    - **Grup sumber daya**: *Pilih atau buat grup sumber daya dengan nama unik*\r\n",
        "    - **Nama**: *Masukkan nama unik*\r\n",
        "    - **Lokasi pelatihan**: *Pilih wilayah yang tersedia*\r\n",
        "    - **Tingkat harga pelatihan**: F0\r\n",
        "    - **Lokasi prediksi**: *Sama dengan lokasi pelatihan*\r\n",
        "    - **Tingkat harga prediksi**: F0\r\n",
        "\r\n",
        "    >Catatan: Jika Anda sudah memiliki layanan custom vision F0 di langganan, pilih **S0** untuk yang satu ini.\r\n",
        "\r\n",
        "3. Tunggu hingga sumber daya dibuat.\r\n",
        "\r\n",
        "## Membuat proyek Custom Vision\r\n",
        "\r\n",
        "Untuk melatih model deteksi objek, Anda harus membuat proyek Custom Vision berdasarkan sumber daya latihan. Untuk melakukannya, Anda akan menggunakan portal Custom Vision.\r\n",
        "\r\n",
        "1. Di tab browser baru, buka portal Custom Vision di [https://customvision.ai](https://customvision.ai), dan masuk menggunakan akun Microsoft yang terkait dengan langganan Azure Anda.\r\n",
        "2. Membuat proyek baru dengan pengaturan berikut:\r\n",
        "    - **Nama**: Deteksi Belanjaan\r\n",
        "    - **Deskripsi**: Deteksi objek untuk belanjaan.\r\n",
        "    - **Sumber daya**: *Sumber daya Custom Vision yang Anda buat sebelumnya*\r\n",
        "    - **Jenis Proyek**: Deteksi Objek\r\n",
        "    - **Domain**: Umum\r\n",
        "3. Tunggu hingga proyek dibuat dan dibuka di browser.\r\n",
        "\r\n",
        "## Menambah dan menandai gambar\r\n",
        "\r\n",
        "Untuk melatih model deteksi objek, Anda harus mengunggah gambar yang berisi kelas yang diinginkan untuk diidentifikasi oleh model, dan menandainya untuk menunjukkan kotak pembatas bagi masing-masing instans objek.\r\n",
        "\r\n",
        "1. Unduh dan ekstrak gambar pelatihan dari https://aka.ms/fruit-objects. Folder yang diekstrak berisi kumpulan gambar buah. **Catatan:** sebagai solusi sementara, jika Anda tidak dapat mengakses gambar pelatihan, buka https://www.github.com, lalu buka https://aka.ms/fruit-objects. \r\n",
        "2. Di portal Custom Vision [https://customvision.ai](https://customvision.ai), pastikan Anda bekerja di proyek deteksi objek _Grocery Detection_. Kemudian pilih **Tambah gambar** dan unggah semua gambar dalam folder yang diekstrak.\r\n",
        "\r\n",
        "![Unggah gambar yang diunduh dengan mengklik tambah gambar.](./images/fruit-upload.jpg)\r\n",
        "\r\n",
        "3. Setelah gambar diunggah, pilih yang pertama untuk membukanya.\r\n",
        "4. Tahan mouse di atas objek apa pun pada gambar hingga wilayah yang terdeteksi secara otomatis ditampilkan seperti gambar di bawah. Lalu pilih objek, dan jika perlu ubah ukuran wilayah di sekitarnya.\r\n",
        "\r\n",
        "![Wilayah default untuk objek](./images/object-region.jpg)\r\n",
        "\r\n",
        "Selain itu, Anda dapat menyeret di sekitar objek untuk membuat wilayah.\r\n",
        "\r\n",
        "5. Bila wilayah mengelilingi objek, tambah tanda baru dengan jenis objek yang sesuai (*apel*, *pisang*, atau *jeruk*) seperti ditampilkan di sini:\r\n",
        "\r\n",
        "![Objek ditandai pada gambar](./images/object-tag.jpg)\r\n",
        "\r\n",
        "6. Pilih dan tandai masing-masing objek lain pada gambar, ubah ukuran wilayah dan tambah tanda baru bila perlu.\r\n",
        "\r\n",
        "![Dua objek ditandai pada gambar](./images/object-tags.jpg)\r\n",
        "\r\n",
        "7. Gunakan tautan **>** di sebelah kanan untuk membuka gambar berikutnya, dan menandai objeknya. Lalu, terus kerjakan hingga seluruh kumpulan gambar, memberi tanda pada setiap apel, pisang, dan jeruk.\r\n",
        "\r\n",
        "8. Saat Anda selesai menandai gambar terakhir, tutup editor **Detal Gambar** dan di halaman **Gambar Pelatihan**, di bawah **Tanda**, pilih **Ditandai** untuk melihat semua gambar yang ditandai:\r\n",
        "\r\n",
        "![Gambar yang ditandai di proyek](./images/tagged-images.jpg)\r\n",
        "\r\n",
        "## Melatih dan menguji model\r\n",
        "\r\n",
        "Sekarang setelah menandai gambar di proyek, Anda siap untuk melatih model.\r\n",
        "\r\n",
        "1. Di proyek Custom Vision, klik **Latih** untuk melatih model deteksi objek menggunakan gambar yang ditandai. Pilih opsi **Pelatihan Cepat**.\r\n",
        "2. Tunggu hingga pelatihan selesai (perlu waktu kurang lebih sepuluh menit), lalu tinjau metrik performa *Presisi*, *Pendahuluan*, dan *mAP* - ketiganya mengukur akurasi prediksi model klasifikasi, dan semuanya harus tinggi.\r\n",
        "3. Di sebelah kanan atas halaman, klik **Uji Cepat**, lalu di kotak **URL Gambar**, masukkan `https://aka.ms/apple-orange` dan lihat prediksi yang dihasilkan. Lalu, tutup jendela **Uji Cepat**.\r\n",
        "\r\n",
        "## Memublikasikan dan mengggunakan model deteksi objek\r\n",
        "\r\n",
        "Sekarang, Anda siap untuk memublikasikan model latihan Anda dan menggunakannya dari aplikasi klien.\r\n",
        "\r\n",
        "1. Di bagian kiri atas halaman **Performa**, klik **&#128504; Publikasikan** untuk memublikasikan model yang telah dilatih dengan pengaturan berikut:\r\n",
        "    - **Nama model**: hasil deteksi\r\n",
        "    - **Sumber Daya Prediksi**: *Sumber daya **prediksi** Custom Vision Anda*.\r\n",
        "\r\n",
        "### (!) Cek Masuk \r\n",
        "Apakah Anda menggunakan nama model yang sama: **hasil deteksi**? \r\n",
        "\r\n",
        "2. Setelah memublikasikan, klik ikon *pengaturan* (&#9881;) di bagian kanan atas halaman **Performa** untuk melihat pengaturan proyek. Lalu, di **Umum** (di kiri), salin **ID Proyek**. Gulir ke bawah dan tempel ke sel kode di bawah langkah 5 menggantikan **YOUR_PROJECT_ID**. \r\n",
        "\r\n",
        "> (*jika Anda menggunakan sumber daya **Cognitive Services** daripada membuat sumber daya **Custom Vision** di awal latihan ini, Anda dapat menyalin kunci dan titik akhirnya dari sisi kanan pengaturan proyek, menempelnya ke sel kode di bawah, dan menjalankannya untuk melihat hasilnya. Jika tidak, lanjutkan menyelesaikan langkah-langkah di bawah untuk mendapatkan kunci dan titik akhir untuk sumber daya prediksi Custom Vision Anda*).\r\n",
        "\r\n",
        "3. Di bagian kiri atas halaman **Pengaturan Proyek**, klik ikon *Galeri Proyek* (&#128065;) untuk kembali ke halaman beranda portal Custom Vision, tempat proyek Anda kini terdaftar.\r\n",
        "\r\n",
        "4. Di halaman beranda portal Custom Vision, di bagian kanan atas, klik ikon *pengaturan* (&#9881;) untuk melihat pengaturan layanan Custom Vision Anda. Lalu, di **Sumber daya**, perluas sumber daya *prediksi* (<u>bukan</u> sumber daya pelatihan) dan salin nilai **Kunci** dan **Titik akhir** tersebut ke sel kode di bawah langkah 5, menggantikan **YOUR_KEY** dan **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Cek Masuk \r\n",
        "Jika Anda menggunakan sumber daya **Custom Vision**, apakah Anda menggunakan sumber daya **prediksi** (<u>bukan</u> sumber daya pelatihan)?\r\n",
        "\r\n",
        "5. Jalankan sel kode di bawah dengan mengeklik tombol Jalankan Sel <span>&#9655;</span> (di bagian kiri atas sel) untuk mengatur variabel ID proyek, kunci dan nilai titik akhir Anda."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID' # Replace with your project ID\r\n",
        "cv_key = 'YOUR_KEY' # Replace with your prediction resource primary key\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT' # Replace with your prediction resource endpoint\r\n",
        "\r\n",
        "model_name = 'detect-produce' # this must match the model name you set when publishing your model iteration exactly (including case)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692485387
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang Anda dapat menggunakan kunci dan titik akhir dengan klien Custom Vision untuk tersambung ke model deteksi objek Custom Vision.\r\n",
        "\r\n",
        "Jalankan sel kode berikut, yang menggunakan model Anda untuk mendeteksi setiap item yang dihasilkan pada gambar.\r\n",
        "\r\n",
        "> **Catatan**: Jangan terlalu khawatir dengan detail kode. Detail kode menggunakan SDK Python untuk layanan Custom Vision guna mengirim gambar ke model dan mengambil prediksi untuk objek yang terdeteksi. Masing-masing prediksi terdiri dari nama kelas (*apel*, *pisang*, atau *jeruk*) dan koordinat *kotak pembatas* yang menunjukkan tempat pada gambar objek yang diprediksi telah terdeteksi. Kemudian, kode menggunakan informasi ini untuk menggambar kotak berlabel di sekitar masing-masing objek pada gambar."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Load a test image and get its dimensions\r\n",
        "test_img_file = os.path.join('data', 'object-detection', 'produce.jpg')\r\n",
        "test_img = Image.open(test_img_file)\r\n",
        "test_img_h, test_img_w, test_img_ch = np.array(test_img).shape\r\n",
        "\r\n",
        "# Get a prediction client for the object detection model\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "predictor = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "print('Detecting objects in {} using model {} in project {}...'.format(test_img_file, model_name, project_id))\r\n",
        "\r\n",
        "# Detect objects in the test image\r\n",
        "with open(test_img_file, mode=\"rb\") as test_data:\r\n",
        "    results = predictor.detect_image(project_id, model_name, test_data)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(8, 8))\r\n",
        "plt.axis('off')\r\n",
        "\r\n",
        "# Display the image with boxes around each detected object\r\n",
        "draw = ImageDraw.Draw(test_img)\r\n",
        "lineWidth = int(np.array(test_img).shape[1]/100)\r\n",
        "object_colors = {\r\n",
        "    \"apple\": \"lightgreen\",\r\n",
        "    \"banana\": \"yellow\",\r\n",
        "    \"orange\": \"orange\"\r\n",
        "}\r\n",
        "for prediction in results.predictions:\r\n",
        "    color = 'white' # default for 'other' object tags\r\n",
        "    if (prediction.probability*100) > 50:\r\n",
        "        if prediction.tag_name in object_colors:\r\n",
        "            color = object_colors[prediction.tag_name]\r\n",
        "        left = prediction.bounding_box.left * test_img_w \r\n",
        "        top = prediction.bounding_box.top * test_img_h \r\n",
        "        height = prediction.bounding_box.height * test_img_h\r\n",
        "        width =  prediction.bounding_box.width * test_img_w\r\n",
        "        points = ((left,top), (left+width,top), (left+width,top+height), (left,top+height),(left,top))\r\n",
        "        draw.line(points, fill=color, width=lineWidth)\r\n",
        "        plt.annotate(prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100),(left,top), backgroundcolor=color)\r\n",
        "plt.imshow(test_img)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692585672
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lihat prediksi yang dihasilkan, yang menampilkan objek terdeteksi dan peluang untuk masing-masing prediksi."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}