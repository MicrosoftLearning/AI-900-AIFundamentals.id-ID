{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mendeteksi dan Menganalisis Wajah\n",
    "\n",
    "Solusi Visi Komputer sering kali memerlukan solusi kecerdasan buatan (AI) agar dapat mendeteksi, menganalisis, atau mengidentifikasi wajah manusia. Misalnya, perusahaan ritel Northwind Traders memutuskan untuk menerapkan \"toko cerdas\", dengan layanan AI yang memantau toko untuk mengidentifikasi pelanggan yang memerlukan bantuan, dan mengarahkan karyawan untuk membantu mereka. Salah satu cara untuk melakukannya adalah dengan melakukan deteksi dan analisis wajah - dengan kata lain, tentukan apakah ada wajah dalam gambar, dan jika demikian, analisis fitur-fiturnya.\n",
    "\n",
    "![Robot menganalisis wajah](./images/face_analysis.jpg)\n",
    "\n",
    "## Menggunakan layanan kognitif Face untuk mendeteksi wajah\n",
    "\n",
    "Misalnya, sistem toko cerdas yang ingin dibuat oleh Northwind Traders harus dapat mendeteksi pelanggan dan menganalisis fitur wajah mereka. Di Microsoft Azure, Anda dapat menggunakan **Face**, bagian dari Cognitive Services Azure untuk melakukan ini.\n",
    "\n",
    "### Membuat Sumber Daya Cognitive Services\n",
    "\n",
    "Mari mulai dengan membuat sumber daya **Cognitive Services** di langganan Azure Anda.\n",
    "\n",
    "> **Catatan**: Jika Anda sudah memiliki sumber daya Cognitive Services, cukup buka halaman Mulai cepat di portal Microsoft Azure dan salin kunci dan titik akhirnya ke sel di bawah. Atau, ikuti langkah-langkah di bawah untuk membuatnya.\n",
    "\n",
    "1. Di tab browser lain, buka portal Microsoft Azure di https://portal.azure.com, masuk menggunakan akun Microsoft Anda.\n",
    "2. Klik tombol **&#65291;Buat sumber daya**, cari *Cognitive Services*, dan buat sumber daya **Cognitive Services** dengan pengaturan berikut:\n",
    "    - **Langganan**: *Langganan Azure Anda*.\n",
    "    - **Grup sumber daya**: *Pilih atau buat grup sumber daya dengan nama unik*.\n",
    "    - **Wilayah**: *Pilih wilayah yang tersedia*:\n",
    "    - **Nama**: *Masukkan nama yang unik*.\n",
    "    - **Tingkat Harga**: S0\n",
    "    - **Saya mengonfirmasi bahwa saya telah membaca dan memahami pemberitahuan tersebut**: Dipilih.\n",
    "3. Tunggu penyebaran hingga selesai. Lalu, buka sumber daya layanan kognitif, dan di halaman **Ringkasan**, klik tautan untuk mengelola kunci layanan. Anda akan memerlukan titik akhir dan kunci untuk terhubung ke sumber daya layanan kognitif Anda dari aplikasi klien.\n",
    "\n",
    "### Mendapatkan Kunci dan Titik Akhir untuk sumber daya Cognitive Services Anda\n",
    "\n",
    "Untuk menggunakan sumber daya layanan kognitif, aplikasi klien memerlukan titik akhir dan kunci autentikasi:\n",
    "\n",
    "1. Di portal Azure, di halaman **Kunci dan Titik Akhir** untuk sumber daya layanan kognitif Anda, salin **Kunci1** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_KEY**.\n",
    "\n",
    "2. Salin **titik akhir** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_ENDPOINT**.\n",
    "\n",
    "3. Jalankan kode pada sel di bawah dengan mengeklik tombol Jalankan Sel <span>&#9655;</span> (di bagian kiri atas sel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang, setelah Anda memiliki sumber daya Cognitive Services, Anda dapat menggunakan layanan Face untuk mendeteksi wajah manusia di toko.\n",
    "\n",
    "Jalankan sel kode di bawah untuk melihat contohnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setiap wajah yang terdeteksi diberi ID unik, sehingga aplikasi Anda dapat mengidentifikasi setiap wajah yang terdeteksi.\n",
    "\n",
    "Jalankan sel di bawah ini untuk melihat ID beberapa wajah pembeli lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menganalisis atribut wajah\n",
    "\n",
    "Face dapat melakukan lebih dari sekadar mendeteksi wajah. Face uga dapat menganalisis fitur dan ekspresi wajah untuk menyarankan umur dan kondisi emosional; Misalnya, jalankan kode di bawah untuk menganalisis atribut wajah pembeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan skor emosi yang terdeteksi untuk pelanggan dalam gambar, pelanggan tampaknya cukup senang dengan pengalaman berbelanja.\n",
    "\n",
    "## Menemukan wajah yang serupa \n",
    "\n",
    "ID wajah yang dibuat untuk setiap wajah yang terdeteksi digunakan untuk mengidentifikasi deteksi wajah satu per satu. Anda dapat menggunakan ID ini untuk membandingkan wajah yang terdeteksi dengan wajah yang sebelumnya terdeteksi dan menemukan wajah dengan fitur serupa.\n",
    "\n",
    "Misalnya, jalankan sel di bawah untuk membandingkan pembeli pada satu gambar dengan pembeli pada gambar lain, dan temukan wajah yang cocok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengenali wajah\n",
    "\n",
    "Sejauh ini, Anda telah melihat bahwa Face dapat mendeteksi wajah dan fitur wajah, dan dapat mengidentifikasi dua wajah yang serupa satu sama lain. Anda dapat melangkah lebih jauh dengan menerapkan solusi *pengenalan wajah* yang melatih Face untuk mengenali wajah orang tertentu. Hal ini dapat berguna dalam berbagai skenario, seperti menandai foto teman secara otomatis di aplikasi media sosial, atau menggunakan pengenalan wajah sebagai bagian dari sistem verifikasi identitas biometrik.\n",
    "\n",
    "Untuk melihat cara kerjanya, misalkan perusahaan Northwind Traders ingin menggunakan pengenalan wajah untuk memastikan bahwa hanya karyawan yang berwenang di departemen TI yang dapat mengakses sistem yang aman.\n",
    "\n",
    "Kita akan mulai dengan membuat *grup orang* untuk mewakili karyawan yang berwenang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang setelah *grup orang* ada, kita dapat menambahkan satu *orang* untuk setiap karyawan yang ingin kita sertakan dalam grup, lalu mendaftarkan beberapa foto dari setiap orang sehingga Face dapat mempelajari karakteristik wajah yang khas dari masing-masing orang. Idealnya, gambar tersebut harus menampilkan orang yang sama dalam pose berbeda dan dengan ekspresi wajah berbeda.\n",
    "\n",
    "Kita akan menambahkan satu karyawan bernama Wendell, dan mendaftarkan tiga foto dari karyawan tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Add a person (Wendell) to the group\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Get photo's of Wendell\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# Register the photos\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # Add each photo to person in person group\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # Display each image\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan orang yang ditambahkan, dan foto-foto yang didaftarkan, kini kita dapat melatih Face untuk mengenali setiap orang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang, dengan model yang telah dilatih, Anda dapat menggunakannya untuk mengidentifikasi wajah yang dikenal pada gambar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# Get the face IDs in a second image\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# Get recognized face names\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# show recognized faces\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pelajari selengkapnya\n",
    "\n",
    "Untuk mempelajari selengkapnya tentang layanan kognitif Face, lihat [dokumentasi Face](https://docs.microsoft.com/azure/cognitive-services/face/)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}