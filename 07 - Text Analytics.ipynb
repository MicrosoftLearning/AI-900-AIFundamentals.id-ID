{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis Teks\r\n",
        "\r\n",
        "NLP (Pemrosesan Bahasa Alami) adalah cabang dari kecerdasan buatan (AI) yang berhubungan dengan bahasa tertulis dan lisan. Anda dapat menggunakan NLP untuk membuat solusi yang mengekstrak arti semantik dari teks atau lisan, atau yang memformulasikan respons bermakna dalam bahasa alami.\r\n",
        "\r\n",
        "*Layanan kognitif* Microsoft Azure mencakup layanan *Analisis Teks*, yang menyediakan beberapa kemampuan NLP yang tidak biasa, termasuk identifikasi frasa kunci dalam teks, dan klasifikasi teks berdasarkan sentimen.\r\n",
        "\r\n",
        "![Robot membaca buku catatan](./images/NLP.jpg)\r\n",
        "\r\n",
        "Misalnya, organisasi fiktif *Margie's Travel* mendorong pelanggan untuk mengirim ulasan tentang menginap di hotel. Anda dapat menggunakan layanan Analisis Teks untuk membuat ringkasan ulasan dengan mengekstrak frasa kunci, menentukan mana ulasan positif dan negatif, atau menganalisis teks ulasan untuk sebutan atas entitas yang diketahui seperti lokasi atau orang.\r\n",
        "\r\n",
        "## Melihat Dokumen Ulasan\r\n",
        "\r\n",
        "Mari mulai dengan memperhatikan beberapa ulasan hotel yang diberikan oleh pelanggan.\r\n",
        "\r\n",
        "Ulasan berada dalam file teks. Untuk melihatnya, cukup jalankan kode di bawah dengan mengeklik tombol **Jalankan sel** (&#9655;) di sebelah kiri sel."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat Sumber Daya Cognitive Services\r\n",
        "\r\n",
        "Untuk menganalisis teks dalam ulasan ini, Anda dapat menggunakan layanan kognitif **Analisis Teks**. Untuk menggunakannya, Anda perlu menyediakan sumber daya **Analisis Teks** atau **Cognitive Services** di langganan Azure (Gunakan sumber daya Analisis Teks jika ini satu-satunya layanan yang Anda rencanakan untuk digunakan atau Anda ingin melacak penggunaannya secara terpisah; atau Anda dapat menggunakan sumber daya Cognitive Services untuk menggabungkan layanan Analisis Teks dengan layanan kognitif lain, memungkinkan pengembang menggunakan kunci dan titik akhir tunggal untuk mengaksesnya.)\r\n",
        "\r\n",
        "Jika Anda belum memilikinya, gunakan langkah-langkah berikut untuk membuat sumber daya **Cognitive Services** di langganan Azure Anda:\r\n",
        "\r\n",
        "> **Catatan**: Jika Anda sudah memiliki sumber daya Cognitive Services, cukup buka halaman Mulai cepat di portal Microsoft Azure dan salin kunci dan titik akhirnya ke sel di bawah. Atau, ikuti langkah-langkah di bawah untuk membuatnya.\r\n",
        "\r\n",
        "1. Di tab browser lain, buka portal Microsoft Azure di https://portal.azure.com, masuk menggunakan akun Microsoft Anda.\r\n",
        "2. Klik tombol **&#65291;Buat sumber daya**, cari *Cognitive Services*, dan buat sumber daya **Cognitive Services** dengan pengaturan berikut:\r\n",
        "    - **Langganan**: *Langganan Azure Anda*.\r\n",
        "    - **Grup sumber daya**: *Pilih atau buat grup sumber daya dengan nama unik*.\r\n",
        "    - **Wilayah**: *Pilih wilayah yang tersedia*:\r\n",
        "    - **Nama**: *Masukkan nama yang unik*.\r\n",
        "    - **Tingkat Harga**: S0\r\n",
        "    - **Saya mengonfirmasi bahwa saya telah membaca dan memahami pemberitahuan tersebut**: Dipilih.\r\n",
        "3. Tunggu penyebaran hingga selesai. Lalu, buka sumber daya layanan kognitif, dan di halaman **Ringkasan**, klik tautan untuk mengelola kunci layanan. Anda akan memerlukan titik akhir dan kunci untuk terhubung ke sumber daya layanan kognitif Anda dari aplikasi klien.\r\n",
        "\r\n",
        "### Mendapatkan Kunci dan Titik Akhir untuk sumber daya Cognitive Services Anda\r\n",
        "\r\n",
        "Untuk menggunakan sumber daya layanan kognitif, aplikasi klien memerlukan titik akhir dan kunci autentikasi:\r\n",
        "\r\n",
        "1. Di portal Azure, di halaman **Kunci dan Titik Akhir** untuk sumber daya layanan kognitif Anda, salin **Kunci1** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_KEY**.\r\n",
        "2. Salin **titik akhir** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_ENDPOINT**.\r\n",
        "3. Jalankan kode pada sel di bawah dengan mengeklik tombol hijau <span style=\"color:green\">&#9655;</span>."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mendeteksi Bahasa\r\n",
        "Mari mulai dengan mengidentifikasi bahasa ulasan ini."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mengekstrak Frasa Kunci\r\n",
        "\r\n",
        "Sekarang Anda dapat menganalisis teks dalam ulasan pelanggan untuk mengidentifikasi frasa kunci yang memberikan beberapa indikasi poin pembicaraan utama."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frasa kunci dapat membantu Anda mendapatkan pemahaman tentang poin pembicaraan paling penting dalam setiap ulasan. Misalnya, sebuah ulasan berisi frasa \"staf yang sangat membantu\" atau \"layanan yang buruk\" dapat memberikan indikasi beberapa keprihatinan utama dari pengulas kepada Anda.\r\n",
        "\r\n",
        "## Menentukan Sentimen\r\n",
        "\r\n",
        "Mungkin berguna untuk mengklasifikasikan ulasan sebagai *positif* atau *negatif* berdasarkan *skor sentimen*. Sekali lagi, Anda dapat menggunakan layanan Analisis Teks untuk melakukan ini."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mengekstrak Entitas yang Telah Diketahui\r\n",
        "\r\n",
        "*Entitas* adalah hal yang bisa jadi disebutkan dalam teks yang merujuk pada beberapa jenis item yang secara umum telah dipahami. Misalnya, lokasi, orang, atau tanggal. Misalnya, Anda tertarik pada tanggal dan tempat yang disebut dalam ulasan, Anda dapat menggunakan kode berikut untuk mencarinya."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhatikan bahwa beberapa entitas cukup dikenal baik memiliki kaitan dengan halaman Wikipedia, dalam hal ini layanan Analisis Teks menampilkan URL untuk halaman tersebut.\r\n",
        "\r\n",
        "## Pelajari selengkapnya\r\n",
        "\r\n",
        "Untuk informasi selengkapnya tentang layanan Analisis Teks, lihat [dokumentasi layanan Analisis Teks](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}