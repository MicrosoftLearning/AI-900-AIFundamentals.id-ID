{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pendahuluan Karakter Optik\r\n",
        "\r\n",
        "![Robot membaca koran](./images/ocr.jpg)\r\n",
        "\r\n",
        "Tantangan visi komputer yang umum adalah mendeteksi dan menafsirkan teks pada gambar. Pemrosesan seperti ini ini sering disebut sebagai *Pendahuluan Karakter Optik (OCR)*.\r\n",
        "\r\n",
        "## Menggunakan Layanan Visi Komputer untuk Membaca Teks dalam Gambar\r\n",
        "\r\n",
        "Layanan kognitif **Visi Komputer** menyediakan dukungan untuk tugas-tugas OCR, termasuk:\r\n",
        "\r\n",
        "- API **OCR** dapat Anda gunakan untuk membaca teks dalam beberapa bahasa. API ini dapat digunakan secara sinkron, dan berfungsi dengan baik saat Anda perlu mendeteksi dan membaca sejumlah kecil teks dalam sebuah gambar.\r\n",
        "- API **Baca** yang dioptimalkan untuk dokumen yang lebih besar. API ini digunakan secara asinkron, dan dapat digunakan untuk teks cetak dan tulisan tangan.\r\n",
        "\r\n",
        "Anda dapat menggunakan layanan ini dengan membuat sumber daya **Visi Komputer** atau sumber daya **Cognitive Services**.\r\n",
        "\r\n",
        "Jika Anda belum melakukannya, buat sumber daya **Cognitive Services** di langganan Azure Anda.\r\n",
        "\r\n",
        "> **Catatan**: Jika Anda sudah memiliki sumber daya Cognitive Services, cukup buka halaman Mulai cepat di portal Microsoft Azure dan salin kunci dan titik akhirnya ke sel di bawah. Atau, ikuti langkah-langkah di bawah untuk membuatnya.\r\n",
        "\r\n",
        "1. Di tab browser lain, buka portal Microsoft Azure  di https://portal.azure.com, masuk menggunakan akun Microsoft Anda.\r\n",
        "\r\n",
        "2. Klik tombol **&#65291;Buat sumber daya**, cari *Cognitive Services*, dan buat sumber daya **Cognitive Services** dengan pengaturan berikut:\r\n",
        "    - **Langganan**: *Langganan Azure Anda*.\r\n",
        "    - **Grup sumber daya**: *Pilih atau buat grup sumber daya dengan nama unik*.\r\n",
        "    - **Wilayah**: *Pilih wilayah yang tersedia*:\r\n",
        "    - **Nama**: *Masukkan nama yang unik*.\r\n",
        "    - **Tingkat Harga**: S0\r\n",
        "    - **Saya mengonfirmasi bahwa saya telah membaca dan memahami pemberitahuan tersebut**: Dipilih.\r\n",
        "3. Tunggu penyebaran hingga selesai. Lalu, buka sumber daya layanan kognitif, dan di halaman **Ringkasan**, klik tautan untuk mengelola kunci layanan. Anda akan memerlukan titik akhir dan kunci untuk terhubung ke sumber daya layanan kognitif Anda dari aplikasi klien.\r\n",
        "\r\n",
        "### Mendapatkan Kunci dan Titik Akhir untuk sumber daya Cognitive Services Anda\r\n",
        "\r\n",
        "Untuk menggunakan sumber daya layanan kognitif, aplikasi klien memerlukan titik akhir dan kunci autentikasi:\r\n",
        "\r\n",
        "1. Di portal Azure, di halaman **Kunci dan Titik Akhir** untuk sumber daya layanan kognitif Anda, salin **Kunci1** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_KEY**.\r\n",
        "2. Salin **titik akhir** untuk sumber daya dan tempel pada kode di bawah, menggantikan **YOUR_COG_ENDPOINT**.\r\n",
        "3. Jalankan kode pada sel di bawah dengan mengeklik tombol **Jalankan sel** (&#9655;) (ke sebelah kiri sel)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694246277
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah menyiapkan kunci dan titik akhir, Anda dapat menggunakan sumber daya layanan visi komputer untuk mengekstrak teks gambar.\r\n",
        "\r\n",
        "Mari kita mulai dengan API **OCR**, yang memungkinkan Anda menganalisis gambar secara sinkron dan membaca isi teksnya. Dalam hal ini, Anda memiliki gambar iklan untuk perusahaan ritel Northwind Traders fiktif yang menyertakan beberapa teks. Jalankan sel di bawah untuk membacanya. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Use the Computer Vision service to find text in the image\r\n",
        "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694257280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teks yang ditemukan dalam gambar diatur ke dalam struktur hierarki wilayah, garis, dan kata, dan kode membacanya untuk mengambil hasilnya.\r\n",
        "\r\n",
        "Di hasil, lihat teks yang dibaca di atas gambar. \r\n",
        "\r\n",
        "## Menampilkan kotak pembatas\r\n",
        "\r\n",
        "Hasil tersebut juga mencakup koordinat *kotak pembatas* untuk baris teks dan masing-masing kata yang ditemukan dalam gambar. Jalankan sel di bawah ini untuk melihat kotak pembatas untuk baris teks pada gambar iklan yang Anda ambil di atas."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Show the position of the line of text\n",
        "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
        "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Show the image with the text locations highlighted\r\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694266106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasilnya, kotak pembatas untuk setiap baris teks ditampilkan sebagai persegi panjang pada gambar.\r\n",
        "\r\n",
        "## Menggunakan API Baca\r\n",
        "\r\n",
        "API OCR yang Anda gunakan sebelumnya berfungsi dengan baik untuk gambar dengan sedikit teks. Saat Anda harus membaca lebih banyak teks, seperti dokumen yang dipindai, Anda dapat menggunakan API **Baca**. Hal ini memerlukan proses beberapa langkah:\r\n",
        "\r\n",
        "1. Kirim gambar ke layanan Visi Komputer untuk dibaca dan dianalisis secara asinkron.\r\n",
        "2. Tunggu hingga operasi analisis selesai.\r\n",
        "3. Ambil hasil analisis tersebut.\r\n",
        "\r\n",
        "Jalankan sel berikut untuk menggunakan proses ini untuk membaca teks dalam surat yang dipindai ke pengelola toko Northwind Traders."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694312346
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tinjau hasilnya. Ada transkripsi lengkap surat tersebut, yang sebagian besar berisi teks cetak dengan tanda tangan tulisan tangan. Gambar asli surat ditampilkan di bawah hasil OCR (Anda harus menggulir ke bawah untuk melihatnya).\r\n",
        "\r\n",
        "## Membaca teks tulisan tangan\r\n",
        "\r\n",
        "Pada contoh sebelumnya, permintaan untuk menganalisis gambar menentukan mode pengenalan teks yang mengoptimalkan operasi untuk teks yang *dicetak*. Perhatikan bahwa meskipun demikian, tanda tangan tulisan tangan ini bisa terbaca.\r\n",
        "\r\n",
        "Kemampuan untuk membaca teks tulisan tangan ini sangat bermanfaat. Misalnya, Anda menulis catatan yang berisi daftar belanja, dan ingin menggunakan aplikasi di ponsel untuk membaca catatan tersebut dan mentranskripsikan teks di dalamnya.\r\n",
        "\r\n",
        "Jalankan sel di bawah untuk melihat contoh operasi baca untuk daftar belanja tulisan tangan."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'note.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694340593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Informasi Selengkapnya\r\n",
        "\r\n",
        "Untuk informasi selengkapnya tentang penggunaan layanan Visi Komputer untuk OCR, lihat [dokumentasi Visi Komputer](https://docs.microsoft.com/id-id/azure/cognitive-services/computer-vision/concept-recognizing-text)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}